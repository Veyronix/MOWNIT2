{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie z Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobieranie danych z Bibli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "path = 'files/bible.txt'\n",
    "bible = open(path,'r')\n",
    "\n",
    "lines = bible.readlines()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział teksu na 1000 dokumentow po 31 zdań oraz wyliczenie bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [[]]\n",
    "bag_of_words = set()\n",
    "\n",
    "index = 0\n",
    "i = 0\n",
    "for line in lines:\n",
    "    p = re.sub('.*:.*\\t','',line).lower()\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  p).split()\n",
    "    documents[index] += wordList\n",
    "    bag_of_words |= set(wordList)\n",
    "    if(i == 31):\n",
    "        index += 1\n",
    "        i = 0\n",
    "        documents.append([])\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obliczenie częstotliwości występowania każdego słowa  z bag_of_words dla każdego dokumentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "doc_word_frequency = []\n",
    "\n",
    "for doc in documents:\n",
    "    dict_bag_of_words = dict.fromkeys(bag_of_words,0)\n",
    "    for word in doc:\n",
    "        dict_bag_of_words.update({word:dict_bag_of_words.get(word)+1})\n",
    "    doc_word_frequency.append(dict_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie term-by-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words_number = len(bag_of_words)\n",
    "term_by_document_matrix = np.zeros((words_number,1000))\n",
    "list_bag_of_words = list(bag_of_words)\n",
    "    \n",
    "def create_term_by_document_matrix():\n",
    "    words_number = len(bag_of_words)\n",
    "    term_by_document_matrix = np.zeros((words_number,1000))\n",
    "    list_bag_of_words = list(bag_of_words)\n",
    "\n",
    "    for i in range(1000):\n",
    "        for index,word in enumerate(list_bag_of_words):\n",
    "            term_by_document_matrix[index,i] = doc_word_frequency[i].get(word)\n",
    "            \n",
    "    return term_by_document_matrix\n",
    "            \n",
    "term_by_document_matrix = create_term_by_document_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redukcja znaczenia często występujących słów\n",
    "(zostanie zastosowana później)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_vector = []\n",
    "\n",
    "N = 1000\n",
    "for index,word in enumerate(list_bag_of_words):\n",
    "    nw = 0\n",
    "    for i in range(N):\n",
    "        if(term_by_document_matrix[index,i] > 0):\n",
    "            nw += 1\n",
    "    if(nw != 0):\n",
    "        idf_vector.append(np.log10(N/nw))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja znajdująca k najbardziej podobnych dokumentów do podanego zapytania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from heapq import nlargest\n",
    "\n",
    "def rate_of_similarity(sentence,k):\n",
    "    query = re.sub(\"[^\\w]\", \" \",  sentence).lower().split()\n",
    "    \n",
    "    query_bag_of_words = dict.fromkeys(bag_of_words,0)\n",
    "    for word in query:\n",
    "        if(word in bag_of_words):\n",
    "            query_bag_of_words.update({word:query_bag_of_words.get(word)+1})\n",
    "    \n",
    "    q = []\n",
    "    for index,word in enumerate(list_bag_of_words):\n",
    "        q.append(query_bag_of_words.get(word))\n",
    "    \n",
    "    similarity_rate = {}\n",
    "    for i in range(1000):\n",
    "        dj = term_by_document_matrix[:,[i]]\n",
    "        q_norm = LA.norm(q)\n",
    "        dj_norm = LA.norm(dj)\n",
    "        cosj = np.dot(q,dj)/(q_norm*dj_norm)\n",
    "        similarity_rate.update({i:cosj})\n",
    "        \n",
    "    return nlargest(k, similarity_rate, key=similarity_rate.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[954,\n",
       " 956,\n",
       " 953,\n",
       " 929,\n",
       " 901,\n",
       " 480,\n",
       " 915,\n",
       " 861,\n",
       " 987,\n",
       " 957,\n",
       " 862,\n",
       " 932,\n",
       " 934,\n",
       " 916,\n",
       " 937,\n",
       " 481,\n",
       " 208,\n",
       " 982,\n",
       " 983,\n",
       " 158]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"God loves you.\"\n",
    "rate_of_similarity(sentence,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[954,\n",
       " 956,\n",
       " 953,\n",
       " 929,\n",
       " 901,\n",
       " 480,\n",
       " 915,\n",
       " 861,\n",
       " 987,\n",
       " 957,\n",
       " 862,\n",
       " 932,\n",
       " 934,\n",
       " 916,\n",
       " 937,\n",
       " 481,\n",
       " 208,\n",
       " 982,\n",
       " 983,\n",
       " 158]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, s, V = np.linalg.svd(term_by_document_matrix, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "np.allclose(term_by_document_matrix, np.dot(U, np.dot(S, V)))\n",
    "term_by_document_matrix = np.dot(U, np.dot(S, V))\n",
    "\n",
    "sentence = \"God loves you.\"\n",
    "rate_of_similarity(sentence,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nie ma różnicy w wynikach przed i po procesie odszumiania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wpływ IDF na wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przed użyciem IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_by_document_matrix = create_term_by_document_matrix()\n",
    "sentence = \"God loves you.\"\n",
    "before_IDF = rate_of_similarity(sentence,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Po użyciu IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[954, 956, 953, 929, 861, 901, 480, 862, 932, 915, 957, 987, 934, 916, 937, 208, 158, 936, 983, 161]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    for j in range(len(idf_vector)):\n",
    "        term_by_document_matrix[j,i] *= idf_vector[j]\n",
    "\n",
    "sentence = \"God loves you.\"      \n",
    "after_IDF = rate_of_similarity(sentence,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[954, 956, 953, 929, 901, 480, 915, 861, 987, 957, 862, 932, 934, 916, 937, 481, 208, 982, 983, 158]\n",
      "[954, 956, 953, 929, 861, 901, 480, 862, 932, 915, 957, 987, 934, 916, 937, 208, 158, 936, 983, 161]\n"
     ]
    }
   ],
   "source": [
    "print(before_IDF)\n",
    "\n",
    "print(after_IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak można zauważyć powyżej, otrzymane wyniki niezbyt się różnią. Niestety ciężko subiektywnie ocenić, który sposób wylicza lepsze rozwiązanie problemu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
